#include "SPHInclude.compute"
#pragma kernel CheckOrder
#pragma kernel LocalCount
#pragma kernel PrecedeScan
#pragma kernel LocalSort
#pragma kernel ComputeGroupKeyOffset
#pragma kernel GlobalReorder

#define SORT_SECTION_SIZE 8
#define SORT_SECTION_SIZE_2D 64
#define LOG2_SORT_SECTION_SIZE_2D 6
#define BITS_PER_ROTATION 4
#define BITS_MASK 15
#define BUCKET_SIZE 16

//Input
uint _SortSectionNum; //please set me
uint _RotationRound; //need to be set every round
StructuredBuffer<Particle> _Particles;

//Update
RWBuffer<uint> _Ordered; //need to be initialized as true
groupshared uint _GroupBucket[BUCKET_SIZE];
RWBuffer<uint> _LocalBinMarkers;//[BUCKET_SIZE * SORT_SECTION_SIZE_2D * Group number]
groupshared uint _GroupBinMarkers[BUCKET_SIZE * SORT_SECTION_SIZE_2D];
groupshared uint _GroupContainer[SORT_SECTION_SIZE_2D];
RWBuffer<uint> _GlobalPrefixSum; //[BUCKET_SIZE]; //need to be initialized as all zeros
RWBuffer<uint> _LocalPrefixSum; //[BUCKET_SIZE * Group number], need to be initialized as all zeros
RWBuffer<uint> _GroupKeyOffset; //[BUCKET_SIZE * Group number]

//Output
RWStructuredBuffer<Particle> _SortedParticles;


[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,1)]
void CheckOrder (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	uint flatIdx = groupIdx + groupId.x * SORT_SECTION_SIZE_2D;
	if(flatIdx >= _ParticleNum - 1)
		return;

	if(_Particles[flatIdx]._cellIdx1d > _Particles[flatIdx + 1]._cellIdx1d)
		InterlockedAnd(_Ordered[0], 0);
}


[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,1)]
void LocalCount (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	if(groupIdx == 0)
	{
		for(int i = 0; i < BUCKET_SIZE; ++i)
			_GroupBucket[i] = 0;
	}
	if(groupId.x == 0)
		_GroupContainer[groupIdx] = 0;
	
	[unroll]
	for(int i = 0; i < BUCKET_SIZE; ++i)
		_LocalBinMarkers[groupIdx + i * SORT_SECTION_SIZE_2D + 
						  groupId.x * BUCKET_SIZE * SORT_SECTION_SIZE_2D] = 0;
	GroupMemoryBarrierWithGroupSync();

	uint flatIdx = groupIdx + groupId.x * SORT_SECTION_SIZE_2D;	
	uint bin = 0;
	if(flatIdx < _ParticleNum)
	{
		//generate local histogram
		bin = (_Particles[flatIdx]._cellIdx1d >> (_RotationRound * BITS_PER_ROTATION)) & BITS_MASK;
		_LocalBinMarkers[groupIdx + bin * SORT_SECTION_SIZE_2D + 
						  groupId.x * BUCKET_SIZE * SORT_SECTION_SIZE_2D] = 1;
		InterlockedAdd(_GroupBucket[bin], 1);
	}
	GroupMemoryBarrierWithGroupSync();
	
	if(groupIdx == 0)
	{
		//compute local prefix sum
		uint counter = 0;
		[unroll]
		for(int i = 0; i < BUCKET_SIZE; ++i)
		{
			uint oldVal = _GroupBucket[i];
			_GroupKeyOffset[BUCKET_SIZE * groupId.x + i] = oldVal;
			_GroupBucket[i] = counter;
			InterlockedAdd(_GlobalPrefixSum[i], _GroupBucket[i]);
			_LocalPrefixSum[BUCKET_SIZE * groupId.x + i] = _GroupBucket[i];
			counter += oldVal;
		}
	}
}

[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,BUCKET_SIZE)]
void PrecedeScan (uint3 threadId : SV_GroupThreadID, uint3 groupId :SV_GroupID)
{
	//threadId.x + threadId.y * SORT_SECTION_SIZE: prev groupIdx
	uint groupIdx = threadId.x + threadId.y * SORT_SECTION_SIZE;
	//threadId.z: bin
	uint bin = threadId.z;
	uint bin_group_offset = bin * SORT_SECTION_SIZE_2D;
	//read to shared memory
	_GroupBinMarkers[groupIdx + bin_group_offset] = 
	_LocalBinMarkers[groupIdx + bin_group_offset + groupId.x * BUCKET_SIZE * SORT_SECTION_SIZE_2D];
	GroupMemoryBarrierWithGroupSync();

	//parallel scan: up-sweep
	int d = 0;
	[unroll]
	for(d = 0; d < LOG2_SORT_SECTION_SIZE_2D - 1; ++d)
	{
		uint pow_2_d_1 = 1 << (d + 1);
		if((groupIdx % pow_2_d_1) == 0)
		{
			_GroupBinMarkers[groupIdx + bin_group_offset + pow_2_d_1 - 1] +=
			_GroupBinMarkers[groupIdx + bin_group_offset + (1 << d) - 1];
		}
		GroupMemoryBarrierWithGroupSync();
	}

	//parallel scan: set last element to zero
	if(groupIdx == SORT_SECTION_SIZE_2D - 1)
	{
		_GroupBinMarkers[groupIdx + bin_group_offset] = 0;
	}
	GroupMemoryBarrierWithGroupSync();

	//parallel scan: down-sweep
	[unroll]
	for(d = LOG2_SORT_SECTION_SIZE_2D - 1; d >= 0; --d)
	{
		uint pow_2_d_1 = 1 << (d + 1);
		uint pow_2_d = (1 << d);
		if((groupIdx % pow_2_d_1) == 0)
		{
			uint old = _GroupBinMarkers[groupIdx + bin_group_offset + pow_2_d - 1];
			_GroupBinMarkers[groupIdx + bin_group_offset + pow_2_d - 1] =
			_GroupBinMarkers[groupIdx + bin_group_offset + pow_2_d_1 - 1];
			_GroupBinMarkers[groupIdx + bin_group_offset + pow_2_d_1 - 1] += old;
		}
		GroupMemoryBarrierWithGroupSync();
	}
	
	//write back to global
	_LocalBinMarkers[groupIdx + bin_group_offset + groupId.x * BUCKET_SIZE * SORT_SECTION_SIZE_2D] =
	_GroupBinMarkers[groupIdx + bin_group_offset];
}

[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,1)]
void LocalSort (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	uint flatIdx = groupIdx + groupId.x * SORT_SECTION_SIZE_2D;
	if(flatIdx < _ParticleNum)
	{
		uint bin = (_Particles[flatIdx]._cellIdx1d >> (_RotationRound * BITS_PER_ROTATION)) & BITS_MASK;
		uint localPos = 
		_LocalPrefixSum[BUCKET_SIZE * groupId.x + bin] + 
		_LocalBinMarkers[groupIdx + bin * SORT_SECTION_SIZE_2D + groupId.x * BUCKET_SIZE * SORT_SECTION_SIZE_2D];
		_SortedParticles[localPos + groupId.x * SORT_SECTION_SIZE_2D] = _Particles[flatIdx];
	}

}

[numthreads(BUCKET_SIZE,1,1)]
void ComputeGroupKeyOffset (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	uint counter = 0;
	for(uint i = 0; i < _SortSectionNum; ++i)
	{
		uint oldVal = _GroupKeyOffset[groupIdx + i * BUCKET_SIZE];
		_GroupKeyOffset[groupIdx + i * BUCKET_SIZE] = counter;
		counter += oldVal;
	}
}

[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,1)]
void GlobalReorder (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	uint flatIdx = groupIdx + groupId.x * SORT_SECTION_SIZE_2D;
	if(flatIdx >= _ParticleNum)
		return;

	uint bin = (_Particles[flatIdx]._cellIdx1d >> (_RotationRound * BITS_PER_ROTATION)) & BITS_MASK;
	uint outIdx = _GlobalPrefixSum[bin] + 
				  _GroupKeyOffset[groupId.x * BUCKET_SIZE + bin] +
				  //local index
				  groupIdx - _LocalPrefixSum[BUCKET_SIZE * groupId.x + bin];

	_SortedParticles[outIdx] = _Particles[flatIdx];
}